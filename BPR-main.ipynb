{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking (BPR) Algorithm with timestamp and rating information\n",
    "\n",
    "### Data Loading with sequence \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoading(filename, splitter):\n",
    "    \"\"\"\n",
    "    Each line of the \"user-item-rate-timestamp\" file is: userId, itemId, ratingScore, timestamp\n",
    "    Each element of train is the [[item1, time1], [item2, time2] of the user, sorted by timestamp\n",
    "    Each element of test  is the [user, item, time] interaction,              sorted by timestamp\n",
    "    \"\"\"\n",
    "    train = []  \n",
    "    test = []\n",
    "    \n",
    "    # load ratings into train\n",
    "    num_ratings = 0\n",
    "    num_item = 0\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        line = f.readline()\n",
    "\n",
    "        # simple note of progress\n",
    "        count += 1\n",
    "        if count%10000 == 0:\n",
    "            sys.stderr.write(\"\\nCurrently at line %d\\n\" % count)\n",
    "            sys.stderr.flush()\n",
    "\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(splitter)\n",
    "            if (len(arr) < 4):\n",
    "                continue\n",
    "            user, item, time = int(arr[0]), int(arr[1]), long(arr[3]) \n",
    "            if (len(train) <= user):\n",
    "                train.append([])\n",
    "            train[user].append([item, time])\n",
    "            num_ratings += 1\n",
    "            num_item = max(item, num_item)\n",
    "            line = f.readline()\n",
    "    num_user = len(train)\n",
    "    num_item = num_item + 1\n",
    "    \n",
    "    # sort ratings of each user by time\n",
    "    def getTime(item):\n",
    "        return item[-1];\n",
    "    for u in range (len(train)):\n",
    "        train[u] = sorted(train[u], key = getTime)\n",
    "    \n",
    "    # split into train/test\n",
    "    for u in range (len(train)):\n",
    "        # for k in range(K):\n",
    "        if (len(train[u]) < 2):\n",
    "        # if (len(train[u]) == 0):\n",
    "            break\n",
    "        test.append([u, train[u][-1][0], train[u][-1][1]])\n",
    "        del train[u][-1]    # delete the last element from train\n",
    "            \n",
    "    # sort the test ratings by time\n",
    "    test = sorted(test, key = getTime)\n",
    "    \n",
    "    return train, test, num_user, num_item, num_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from MFbpr import MFbpr\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Try loading a sample dataset.\n",
    "# dataset = 'data/yelp.rating'\n",
    "# # dataset = '/Users/ito/venv/pyspark-rec/ml-100k/u.data' # need to shift (i.e., -1) on ID\n",
    "# splitter = \"\\t\"\n",
    "# train, test, num_user, num_item, num_ratings = DataLoading(dataset, splitter)\n",
    "# sys.stderr.write(\"Load data (%s) done.\\n\" %(dataset))\n",
    "# sys.stderr.write(\"#users: %d, #items: %d, #ratings: %d\" %(num_user, num_item, num_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load .csv transaction data (I am showing Tops as an example, while I am thinking of processing shopping mall data since I hope to have a category information that is already \"provided\" in shopping mall product_master.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShoppingMall = pd.read_csv('/Users/ito/venv/CG-RecoEng/data/SM-focus.csv', sep=',', engine='c')\n",
    "# data = ShoppingMall\n",
    "Tops_trans_df = pd.read_csv('/Users/ito/venv/CG-RecoEng/data/og_data/Tops_supermarket.csv', \n",
    "                            parse_dates=['TransactionDate'], sep=',', engine='c')\n",
    "data = Tops_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1995491, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TypeGroup</th>\n",
       "      <th>BUID</th>\n",
       "      <th>BranchID</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CardNo</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>SKUCode</th>\n",
       "      <th>Spending</th>\n",
       "      <th>DeptCode</th>\n",
       "      <th>SubDeptCode</th>\n",
       "      <th>QTY</th>\n",
       "      <th>tDate2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>4294</td>\n",
       "      <td>2017-02-27 20:12:00</td>\n",
       "      <td>312CB58B-09B6-49CA-9F1D-AEF8D56E3F4E</td>\n",
       "      <td>8035450104</td>\n",
       "      <td>40155510</td>\n",
       "      <td>8851954101211</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>2865</td>\n",
       "      <td>2017-01-18 12:28:00</td>\n",
       "      <td>35FFAE65-80FA-4A2B-8F05-98ACAE82EF86</td>\n",
       "      <td>8028520371</td>\n",
       "      <td>80176812</td>\n",
       "      <td>8851717901607</td>\n",
       "      <td>100.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TypeGroup  BUID  BranchID     TransactionDate  \\\n",
       "0          1   150      4294 2017-02-27 20:12:00   \n",
       "1          1   150      2865 2017-01-18 12:28:00   \n",
       "\n",
       "                             CustomerID      CardNo  TicketNumber  \\\n",
       "0  312CB58B-09B6-49CA-9F1D-AEF8D56E3F4E  8035450104      40155510   \n",
       "1  35FFAE65-80FA-4A2B-8F05-98ACAE82EF86  8028520371      80176812   \n",
       "\n",
       "         SKUCode  Spending  DeptCode  SubDeptCode  QTY      tDate2  \n",
       "0  8851954101211     17.00       1.0          3.0    1  2017-02-27  \n",
       "1  8851717901607    100.39       1.0          4.0    2  2017-01-18  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Tops_trans_df.shape\n",
    "Tops_trans_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, the file below (ProductMaster is with category information while ProductMaster_Tops is with details (except pricing info which we concerned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# productfile1 = '/Users/ito/venv/CG-RecoEng/data/og_data/ProductMaster.csv'\n",
    "# product1 = pd.read_csv(productfile1, sep=',', engine='c')\n",
    "productfile2 = '/Users/ito/venv/CG-RecoEng/data/og_data/ProductMaster_Tops.csv'\n",
    "product2 = pd.read_csv(productfile2, sep=',', engine='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling to the certain tuple based format with timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1995491, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerCat</th>\n",
       "      <th>ItemCat</th>\n",
       "      <th>QTY</th>\n",
       "      <th>OrdinalTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1785</td>\n",
       "      <td>31637</td>\n",
       "      <td>1</td>\n",
       "      <td>736387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971</td>\n",
       "      <td>30314</td>\n",
       "      <td>2</td>\n",
       "      <td>736347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7656</td>\n",
       "      <td>40054</td>\n",
       "      <td>1</td>\n",
       "      <td>736398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>595</td>\n",
       "      <td>25826</td>\n",
       "      <td>1</td>\n",
       "      <td>736363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6470</td>\n",
       "      <td>13776</td>\n",
       "      <td>1</td>\n",
       "      <td>736375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerCat  ItemCat  QTY  OrdinalTime\n",
       "0         1785    31637    1       736387\n",
       "1         1971    30314    2       736347\n",
       "2         7656    40054    1       736398\n",
       "3          595    25826    1       736363\n",
       "4         6470    13776    1       736375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the data that follows the timestamp format\n",
    "# type(data.TransactionDate[0])\n",
    "data['OrdinalTime'] = data.TransactionDate.map(pd._libs.tslib.Timestamp.toordinal)\n",
    "\n",
    "idx = pd.Categorical(list(data.CustomerID)).codes\n",
    "itm = pd.Categorical(list(data.SKUCode)).codes\n",
    "\n",
    "data['CustomerCat'] = idx #+1\n",
    "data['ItemCat'] = itm #+1\n",
    "sub_data = data[['CustomerCat','ItemCat','QTY','OrdinalTime']]\n",
    "\n",
    "print sub_data.shape\n",
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = sub_data.sort_values(by=['CustomerCat','ItemCat'])\n",
    "# sub_data.to_csv('Tops_user-item_data', index=False,header=False, sep='\\t')\n",
    "sub_data.to_csv('Tops_BPR_2_data.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the ID and the \"series number\" by zipping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_match = zip(data.CustomerID, data['CustomerCat'] )\n",
    "itm_match = zip(data.SKUCode, data['ItemCat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('312CB58B-09B6-49CA-9F1D-AEF8D56E3F4E', 1785),\n",
       " ('35FFAE65-80FA-4A2B-8F05-98ACAE82EF86', 1971),\n",
       " ('D2F9C8EA-51C7-4824-B7F5-9ADAAE665EDB', 7656),\n",
       " ('0FEF3D2E-DFF0-4CAF-8CB2-471FF2404348', 595),\n",
       " ('B1E1C8CF-D484-4141-89A5-D24C570EF70A', 6470)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_match[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8851954101211, 31637),\n",
       " (8851717901607, 30314),\n",
       " (8858935387008, 40054),\n",
       " (8850329315543, 25826),\n",
       " (4005808695829, 13776)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itm_match[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare matching lists (saved to files also)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995491\n",
      "44057\n"
     ]
    }
   ],
   "source": [
    "itm_match.sort()\n",
    "print itm_match.__len__()\n",
    "itm_final = set(itm_match)\n",
    "print itm_final.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995491\n",
      "9204\n"
     ]
    }
   ],
   "source": [
    "idx_match.sort()\n",
    "print idx_match.__len__()\n",
    "idx_final = set(idx_match)\n",
    "print idx_final.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = list(idx_final)\n",
    "ITM = list(itm_final)\n",
    "IDX.sort()\n",
    "ITM.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(IDX).to_csv('user_matching_list', index=False,header=False, sep='\\t')\n",
    "pd.DataFrame(ITM).to_csv('item_matching_list', index=False,header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load data (Tops_BPR_2_data.csv) done.#users: 9204, #items: 44057, #ratings: 1995491"
     ]
    }
   ],
   "source": [
    "dataset = 'Tops_BPR_2_data.csv'\n",
    "splitter = \",\"\n",
    "train, test, num_user, num_item, num_ratings = DataLoading(dataset, splitter)\n",
    "sys.stderr.write(\"Load data (%s) done.\" %(dataset))\n",
    "sys.stderr.write(\"#users: %d, #items: %d, #ratings: %d\" %(num_user, num_item, num_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the parameters for bpr with multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = 10\n",
    "learning_rate = 0.01\n",
    "reg = 0.01\n",
    "init_mean = 0\n",
    "init_stdev = 0.01\n",
    "maxIter = 50\n",
    "num_thread = mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = MFbpr(train, test, num_user, num_item, factors, learning_rate, reg, init_mean, init_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of user = 9204\n",
      "Training MF-BPR with: learning_rate=0.01, regularization=0.0100, factors=10, #epoch=50, batch_size=1000.\n",
      "Iter=0 [59.5 s] HitRatio@100 = 0.017, NDCG@100 = 0.004 [0.5 s]\n",
      "Iter=1 [57.4 s] HitRatio@100 = 0.045, NDCG@100 = 0.008 [0.6 s]\n",
      "Iter=2 [57.6 s] HitRatio@100 = 0.049, NDCG@100 = 0.010 [0.8 s]\n",
      "Iter=3 [57.0 s] HitRatio@100 = 0.056, NDCG@100 = 0.011 [0.8 s]\n",
      "Iter=4 [54.6 s] HitRatio@100 = 0.059, NDCG@100 = 0.013 [0.8 s]\n",
      "Iter=5 [56.1 s] HitRatio@100 = 0.059, NDCG@100 = 0.014 [0.9 s]\n",
      "Iter=6 [57.0 s] HitRatio@100 = 0.059, NDCG@100 = 0.014 [0.8 s]\n",
      "Iter=7 [57.1 s] HitRatio@100 = 0.059, NDCG@100 = 0.012 [0.8 s]\n",
      "Iter=8 [55.8 s] HitRatio@100 = 0.063, NDCG@100 = 0.013 [0.9 s]\n",
      "Iter=9 [56.9 s] HitRatio@100 = 0.063, NDCG@100 = 0.013 [0.9 s]\n",
      "Iter=10 [57.0 s] HitRatio@100 = 0.066, NDCG@100 = 0.014 [0.8 s]\n",
      "Iter=11 [57.0 s] HitRatio@100 = 0.052, NDCG@100 = 0.011 [0.8 s]\n",
      "Iter=12 [57.0 s] HitRatio@100 = 0.073, NDCG@100 = 0.014 [0.9 s]\n",
      "Iter=13 [57.0 s] HitRatio@100 = 0.063, NDCG@100 = 0.012 [0.9 s]\n",
      "Iter=14 [56.9 s] HitRatio@100 = 0.063, NDCG@100 = 0.013 [0.9 s]\n",
      "Iter=15 [57.0 s] HitRatio@100 = 0.063, NDCG@100 = 0.014 [0.9 s]\n",
      "Iter=16 [56.4 s] HitRatio@100 = 0.059, NDCG@100 = 0.012 [0.9 s]\n",
      "Iter=17 [55.0 s] HitRatio@100 = 0.063, NDCG@100 = 0.013 [0.8 s]\n",
      "Iter=18 [57.0 s] HitRatio@100 = 0.063, NDCG@100 = 0.014 [0.9 s]\n",
      "Iter=19 [55.8 s] HitRatio@100 = 0.063, NDCG@100 = 0.014 [0.9 s]\n",
      "Iter=20 [56.9 s] HitRatio@100 = 0.070, NDCG@100 = 0.016 [0.9 s]\n",
      "Iter=21 [56.4 s] HitRatio@100 = 0.056, NDCG@100 = 0.013 [0.9 s]\n",
      "Iter=22 [56.8 s] HitRatio@100 = 0.066, NDCG@100 = 0.015 [0.9 s]\n",
      "Iter=23 [57.0 s] HitRatio@100 = 0.063, NDCG@100 = 0.015 [0.9 s]\n",
      "Iter=24 [56.9 s] HitRatio@100 = 0.063, NDCG@100 = 0.015 [0.9 s]\n",
      "Iter=25 [56.3 s] HitRatio@100 = 0.070, NDCG@100 = 0.017 [0.9 s]\n",
      "Iter=26 [56.9 s] HitRatio@100 = 0.070, NDCG@100 = 0.017 [0.9 s]\n",
      "Iter=27 [57.0 s] HitRatio@100 = 0.070, NDCG@100 = 0.017 [0.9 s]\n",
      "Iter=28 [57.0 s] HitRatio@100 = 0.066, NDCG@100 = 0.017 [0.9 s]\n",
      "Iter=29 [56.8 s] HitRatio@100 = 0.063, NDCG@100 = 0.016 [0.9 s]\n",
      "Iter=30 [57.0 s] HitRatio@100 = 0.080, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=31 [56.8 s] HitRatio@100 = 0.080, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=32 [56.8 s] HitRatio@100 = 0.066, NDCG@100 = 0.016 [0.9 s]\n",
      "Iter=33 [57.0 s] HitRatio@100 = 0.066, NDCG@100 = 0.018 [1.0 s]\n",
      "Iter=34 [54.9 s] HitRatio@100 = 0.070, NDCG@100 = 0.017 [1.0 s]\n",
      "Iter=35 [56.9 s] HitRatio@100 = 0.073, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=36 [56.9 s] HitRatio@100 = 0.070, NDCG@100 = 0.018 [1.0 s]\n",
      "Iter=37 [55.1 s] HitRatio@100 = 0.077, NDCG@100 = 0.019 [1.0 s]\n",
      "Iter=38 [56.4 s] HitRatio@100 = 0.066, NDCG@100 = 0.018 [1.0 s]\n",
      "Iter=39 [56.9 s] HitRatio@100 = 0.070, NDCG@100 = 0.019 [1.0 s]\n",
      "Iter=40 [56.6 s] HitRatio@100 = 0.073, NDCG@100 = 0.022 [1.0 s]\n",
      "Iter=41 [57.0 s] HitRatio@100 = 0.077, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=42 [56.9 s] HitRatio@100 = 0.077, NDCG@100 = 0.021 [1.0 s]\n",
      "Iter=43 [56.9 s] HitRatio@100 = 0.073, NDCG@100 = 0.021 [1.0 s]\n",
      "Iter=44 [56.9 s] HitRatio@100 = 0.077, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=45 [56.9 s] HitRatio@100 = 0.080, NDCG@100 = 0.020 [1.0 s]\n",
      "Iter=46 [56.8 s] HitRatio@100 = 0.084, NDCG@100 = 0.021 [1.0 s]\n",
      "Iter=47 [56.9 s] HitRatio@100 = 0.073, NDCG@100 = 0.018 [1.1 s]\n",
      "Iter=48 [54.0 s] HitRatio@100 = 0.077, NDCG@100 = 0.022 [1.1 s]\n",
      "Iter=49 [57.1 s] HitRatio@100 = 0.084, NDCG@100 = 0.022 [1.0 s]\n",
      "time elapsed: 2879.93985105\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "starting = time.time()\n",
    "\n",
    "# bpr.build_model(maxIter, num_thread, batch_size=32)\n",
    "bpr.build_model(maxIter, num_thread, batch_size=1000)\n",
    "\n",
    "ending = time.time()\n",
    "print 'time elapsed: ' + str(ending - starting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of single prediction -- affinity(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7778526114505753"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.predict(test[0][0],test[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of multi prediction -- affinity(user, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.88487989, -1.76849832, -1.89922613, ..., -1.59746948,\n",
       "       -1.72308219, -1.81282518])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.predictions(test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return the top 5 item of interest for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "res = []\n",
    "top_howmany = 5\n",
    "for k in range(num_user):\n",
    "    temp_pred = bpr.predictions(k)\n",
    "    top_list = heapq.nlargest(top_howmany,temp_pred)\n",
    "    res.append([i for i in range(len(temp_pred)) if temp_pred[i] in top_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "itm_match = zip(data['ItemCat'],data.SKUCode)\n",
    "itm_dict = dict(itm_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate category ID to SKUID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_SKUID(input):\n",
    "    return [itm_dict[input[0]], itm_dict[input[1]], itm_dict[input[2]], itm_dict[input[3]], itm_dict[input[4]]]\n",
    "\n",
    "res_SKUID = res_df.apply(return_SKUID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_match = zip(product2.SKUID,product2.PRODUCT_ENG_DESC)\n",
    "sku_dict = dict(sku_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_desc(input):\n",
    "    return [sku_dict[input[0]], sku_dict[input[1]], sku_dict[input[2]], sku_dict[input[3]], sku_dict[input[4]]]\n",
    "\n",
    "res_desc = res_SKUID.apply(return_desc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9204, 5)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(heapq.nlargest(3,nums))\n",
    "lst = [0,1,3,11,0]\n",
    "some = [i for i in range(len(lst)) if lst[i] in heapq.nlargest(3,lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstmfile = '/Users/ito/venv/CG-RecoEng/data/og_data/Customer_Profile.csv'\n",
    "customer = pd.read_csv(cstmfile, sep=',', engine='c')\n",
    "\n",
    "def strip_brace(input):\n",
    "#     input = input.strip('{')\n",
    "#     input = input.strip('}')\n",
    "    return input[1:-1]\n",
    "#     return input\n",
    "\n",
    "customer.CustomerID = customer.CustomerID.map(strip_brace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_sorted = customer.sort_values(by='CustomerID')\n",
    "customer_sorted = customer_sorted.reset_index()\n",
    "customer_sub = customer_sorted[['CustomerID','DateofBirth','Nationality','Gender','MaritalStatus','NoofChildren','HaveOnlineaccount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_sub\n",
    "Reco_result = pd.concat([customer_sub, res_desc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reco_result.to_csv('Reco_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "### Efficiency test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@exeTime\n",
    "def predict1(bpr, u, i):\n",
    "    res = np.inner(bpr.U_np[u], bpr.V_np[i])\n",
    "    return res\n",
    "\n",
    "@exeTime\n",
    "def predict2(bpr, u, i):\n",
    "    res = T.dot(bpr.U[u], bpr.V[i]).eval()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exeTime(func):\n",
    "    def newFunc(*args, **args2):\n",
    "        t0 = time.time()\n",
    "        print \"@%s, {%s} start\" % (time.strftime(\"%X\", time.localtime()), func.__name__)\n",
    "        back = func(*args, **args2)\n",
    "        print \"@%s, {%s} end\" % (time.strftime(\"%X\", time.localtime()), func.__name__)\n",
    "        print \"@%.3fs taken for {%s}\" % (time.time() - t0, func.__name__)\n",
    "        return back\n",
    "    return newFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = np.linspace(1,100,10000000)\n",
    "\n",
    "%%cython\n",
    "def c_add(int a, int b):\n",
    "    cdef int s = a+b\n",
    "    return s\n",
    "\n",
    "def p_add(a,b):\n",
    "    return a+b\n",
    "\n",
    "%%cython\n",
    "def cython_mean(double[:] x):\n",
    "    cdef double total = 0\n",
    "    for i in range(len(x)):\n",
    "        total += x[i]\n",
    "    return total / len(x)\n",
    "\n",
    "def python_mean(xs):\n",
    "    total = 0\n",
    "    for i in range(len(xs)):\n",
    "        total += xs[i]\n",
    "    return total/len(xs)\n",
    "\n",
    "from numba import jit\n",
    "@jit\n",
    "def numba_mean(xs):\n",
    "    total = 0\n",
    "    for i in range(len(xs)):\n",
    "        total += xs[i]\n",
    "    return total/len(xs)\n",
    "\n",
    "\n",
    "%timeit python_mean(alist)\n",
    "%timeit cython_mean(alist)\n",
    "\n",
    "%timeit np.mean(alist)\n",
    "\n",
    "%timeit numba_mean(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing mem for data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.QTY = sub_data.QTY.astype(np.int16)\n",
    "sub_data.OrdinalTime = sub_data.OrdinalTime.astype(np.int32)\n",
    "sub_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
