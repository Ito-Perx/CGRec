{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark recommendation engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have noted with Vidyut that currently we have to build method-pool instead of rules. (Notes are in separated email.)\n",
    "\n",
    "* Here we illustrate the PySpark env with CF(ALS) and BPR using our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env\n",
    "from pyspark import SparkConf, SparkContext \n",
    "\n",
    "# methods\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from bpr_spark.bpr import bprMF\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# result processing\n",
    "import math\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fuction translates the data into RDD rating format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(str):  \n",
    "    arr = str.split('\\t') \n",
    "    user_id = int(arr[0])  \n",
    "    movie_id = int(arr[1])  \n",
    "    user_rating = float(arr[2])  \n",
    "    return Rating(user_id, movie_id, user_rating)\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Spark Context (cannot be reset once set well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'999\\t7071\\t1\\t736433', u'999\\t7070\\t1\\t736433', u'999\\t6951\\t1\\t736485']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf().setMaster('local').setAppName('RecoEng').set(\"spark.executor.memory\", \"8g\")  \n",
    "sc = SparkContext(conf=conf)\n",
    "data = sc.textFile('/Users/ito/venv/pyspark-rec/CG-Tops/Tops_user-item_data')  \n",
    "data.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=9204, product=43518, rating=1.0),\n",
       " Rating(user=9204, product=43392, rating=2.0),\n",
       " Rating(user=9204, product=43378, rating=1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because for mllib.recommendation, there is already data structure running on it\n",
    "ratings = data.map(get_rating) \n",
    "ratings.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris # iris数据集\n",
    "# from sklearn.model_selection import train_test_split # 分割数据模块\n",
    "# from sklearn.neighbors import KNeighborsClassifier # K最近邻(kNN，k-NearestNeighbor)分类算法\n",
    "# from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "# # import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "# # import pyspark..recommendation import ALS, Rating\n",
    "# # val data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_linear_regression_data.txt\")\n",
    "# training__, test__ = ratings.randomSplit([0.9, 0.1], seed = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Collaborative Filtering \n",
    "* using Alternating Least Squares (ALS) optimization\n",
    "* call java function \"trainALSModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [0.9, 0.1]\n",
    "ratings_cf_train, ratings_cf_test = ratings.randomSplit(split, seed = 225)\n",
    "\n",
    "ratings2 = data.map(lambda line: line.split(\"\\t\")).map(lambda x: map(int, x[:2]))\n",
    "ratings_bpr_train, ratings_bpr_test = ratings2.randomSplit([0.9, 0.1], seed = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CollaborativeFiltering(ratings, rank = 10, iterations = 5):\n",
    "    model = ALS.train(ratings, rank, iterations)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 4.51 ms, total: 16.5 ms\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CFmodel = CollaborativeFiltering(ratings_cf_train,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 4.49 ms, total: 16.5 ms\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rank = 10  \n",
    "iterations = 5    \n",
    "ALSmodel = ALS.train(ratings, rank, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalability and efficiency of pySpark is going well, and even it is not CPU-wise multiprocessed. So far so good, means my next step is towards accuracy and realistic level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.94 ms, sys: 3.67 ms, total: 12.6 ms\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CFmodel_ = CollaborativeFiltering(ratings,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Bayesian Personalized Ranking (for PySpark)\n",
    "* optimized using Stochastic Gradient Descent (SGD, cannot be as simply paralled as ALS)  \n",
    "* have remained only user-item information yet (the basic BPR or say BPR-1)\n",
    "* return 2 matrices (user matrix with (#user,k), item matrix with (k,#item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = SparkConf().setMaster(\"local\").setAppName(\"BPR\").set(\"spark.executor.memory\", \"8g\")\n",
    "# sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = sc.textFile(\"/Users/ito/venv/pyspark-rec/CG-Tops/Tops_user-item_data\")\n",
    "# ratings = data.map(lambda line: line.split(\"\\t\")).map(lambda x: map(int, x[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 920 ms, sys: 873 ms, total: 1.79 s\n",
      "Wall time: 12min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# bprMF(ratings, rank, num_iter=10, num_neg_samples=30):\n",
    "userMat, prodMat = bprMF(ratings_bpr_train, 10, 20, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** Building another version that can run faster (MR for map reduce) (to be continued..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bpr_spark.distbpr import bpr_MF_MR\n",
    "# userMat2, prodMat2 = bpr_MF_MR(ratings, 10, 10)\n",
    "# userMat2, prodMat2 = bpr_MF_MR(ratings, 10, 10, nb_partitions = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = 10\n",
    "rec_items_bpr = np.inner(userMat[userid].T, prodMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually do the similar showcasing like \"ALSmodel.recommendProducts(userid, top_howmany)\" using heap sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5565</td>\n",
       "      <td>43.066266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2560</td>\n",
       "      <td>35.460403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>18536</td>\n",
       "      <td>34.197045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>18506</td>\n",
       "      <td>31.236967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>18508</td>\n",
       "      <td>29.732398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  product     rating\n",
       "0    10     5565  43.066266\n",
       "1    10     2560  35.460403\n",
       "2    10    18536  34.197045\n",
       "3    10    18506  31.236967\n",
       "4    10    18508  29.732398"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_howmany = 5\n",
    "res = []\n",
    "top_list = heapq.nlargest(top_howmany,rec_items_bpr)\n",
    "res.append([i for i in range(len(rec_items_bpr)) if rec_items_bpr[i] in top_list])\n",
    "\n",
    "userid = 10\n",
    "rec_items = CFmodel.recommendProducts(userid, top_howmany)  \n",
    "\n",
    "pd.DataFrame(rec_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple result from Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend items for userid 10:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=10, product=5565, rating=43.066266262561186),\n",
       " Rating(user=10, product=2560, rating=35.46040302641053),\n",
       " Rating(user=10, product=18536, rating=34.19704472498653),\n",
       " Rating(user=10, product=18506, rating=31.236967455736426),\n",
       " Rating(user=10, product=18508, rating=29.732397625435627)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('recommend items for userid %d:' % userid)\n",
    "[i for i in rec_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple result from Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend items for userid 10:\n",
      "user=10, product=108, rating=251.157254\n",
      "user=10, product=1226, rating=32.101318\n",
      "user=10, product=6945, rating=17.967807\n",
      "user=10, product=11419, rating=14.482411\n",
      "user=10, product=37100, rating=13.816158\n"
     ]
    }
   ],
   "source": [
    "print ('recommend items for userid %d:' % userid)\n",
    "for idx, i in enumerate(res[0]):\n",
    "    print 'user=%d, ' % userid + 'product=%d, ' % i  + 'rating=%f' % top_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userMat.shape\n",
    "# num_users = ratings2.map(lambda x: x[0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.9 ms, sys: 9.53 ms, total: 72.5 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rec_items_cf_ = []\n",
    "rec_items_bpr_ = []\n",
    "for i in range(1, 4):\n",
    "    rec_items_cf_.extend(CFmodel_.recommendProducts(i, top_howmany)) \n",
    "    \n",
    "    rec_items_bpr = np.inner(userMat[i].T, prodMat)\n",
    "    top_list = heapq.nlargest(top_howmany,rec_items_bpr)\n",
    "    \n",
    "    idx = 0\n",
    "    for j in range(len(rec_items_bpr)):\n",
    "        if rec_items_bpr[j] in top_list:\n",
    "            rec_items_bpr_.append((i, j, top_list[idx])) \n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. FM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting on test_set for each method considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_howmany = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gathering recommending result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing\n",
    "# %%time\n",
    "# # CFmodel_.recommendProducts(1, top_howmany)\n",
    "# userid = 10\n",
    "# rec_items_bpr = np.inner(userMat[userid].T, prodMat)\n",
    "# res = []\n",
    "# top_list = heapq.nlargest(top_howmany,rec_items_bpr)\n",
    "# res.append([i for i in range(len(rec_items_bpr)) if rec_items_bpr[i] in top_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Blackboxing the recommendProducts from BPR side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_recommendProducts(userID, top_howmany = 5):\n",
    "    rec_items_bpr = np.inner(userMat[userID].T, prodMat)\n",
    "    res_4_userID = []\n",
    "    top_list = heapq.nlargest(top_howmany,rec_items_bpr)\n",
    "\n",
    "    idx = 0\n",
    "    for j in range(len(rec_items_bpr)):\n",
    "        if rec_items_bpr[j] in top_list:\n",
    "            res_4_userID.append((userID, j, top_list[idx])) \n",
    "            idx += 1\n",
    "    return res_4_userID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_items_cf = []\n",
    "rec_items_bpr = []\n",
    "for i in range(1, userMat.shape[0]):\n",
    "    rec_items_cf.extend(CFmodel_.recommendProducts(i, top_howmany)) \n",
    "    rec_items_bpr.extend(bpr_recommendProducts(i, top_howmany)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Result regularizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_res_df = pd.DataFrame(rec_items_cf)\n",
    "cf_devider = np.mean(cf_res_df.groupby('user').rating.max())\n",
    "cf_res_df['rating'] = cf_res_df.rating/cf_devider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_res_df = pd.DataFrame(rec_items_bpr)\n",
    "bpr_res_df.columns = cf_res_df.columns\n",
    "bpr_devider = np.mean(bpr_res_df.groupby('user').rating.max())\n",
    "bpr_res_df['rating'] = bpr_res_df.rating/bpr_devider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generating overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.concat([cf_res_df,bpr_res_df])\n",
    "overall_df_show = overall_df.groupby(['user','product']).rating.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting the most possible recommendations (from mid of the top values -- avoid overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taking_out_reco_pairs(input_pairs, num = 7, init_pos = 7):\n",
    "    _pairs_items = input_pairs.sort_values(ascending=False).index\n",
    "    if len(_pairs_items)<init_pos+num:\n",
    "        return _pairs_items[-num:]\n",
    "    return _pairs_items[init_pos:init_pos+num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_result = []\n",
    "for i in range(1,userMat.shape[0]):\n",
    "    overall_result.append([i, list(taking_out_reco_pairs(overall_df_show[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hit Ratio evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHit(input_tuple):\n",
    "    user = input_tuple[0]\n",
    "    item = input_tuple[1]\n",
    "    \n",
    "    for reco_item in overall_result[user-1][1]:\n",
    "        if reco_item == item:\n",
    "            return 7\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NDCG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNDCG(input_tuple):\n",
    "    user = input_tuple[0]\n",
    "    item = input_tuple[1]\n",
    "    \n",
    "    for idx, reco_item in enumerate(overall_result[user-1][1]):\n",
    "        if reco_item == item:\n",
    "            return 2*math.log(2)/math.log(idx+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio is with (%100): 0.0927863381098\n",
      "NDCG is with: 0.0102016107188\n"
     ]
    }
   ],
   "source": [
    "print 'Hit Ratio is with (%100): ' + str(ratings_bpr_test.map(getHit).sum()*1.0/ratings_test.__len__())\n",
    "print 'NDCG is with: ' + str(ratings_bpr_test.map(getNDCG).sum()/ratings_test.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
